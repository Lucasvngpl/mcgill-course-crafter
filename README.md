# mcgill-course-crafter ğŸš€â€‹

An intelligent course planning assistant for McGill University students. Ask natural language questions about prerequisites, corequisites, and course sequences â€” get accurate answers grounded in real catalogue data.

**Live Demo:** [[mcgill-course-crafter.vercel.app](https://mcgill-course-crafter.vercel.app)](https://mcgill-course-crafter.vercel.app/)

---

## What It Does

McGill's course catalogue is a maze. CourseCraft AI makes it simple:

```
You: "Can I take COMP 273 after taking COMP 206?"

CourseCraft AI: "Yes! COMP 206 is a corequisite for COMP 273, meaning you can 
Take COMP 273 at the same time as COMP 206, or any semester after completing it."
```

The system understands the difference between:
- **Prerequisites** â€” must complete *before* taking a course
- **Corequisites** â€” can take *at the same time* or *after* completing

---

## Features

- **Natural Language Q&A** â€” Ask questions like you'd ask an advisor
- **8,000+ Courses Indexed** â€” Scraped from McGill's official catalog
- **Hybrid Search** â€” Combines semantic vector search with deterministic SQL lookups
- **Corequisite-Aware Logic** â€” Understands nuanced academic rules most systems miss

---

## Tech Stack â€‹ğŸ–¥ï¸â€‹

| Layer | Technology |
|-------|------------|
| **Frontend** | React, TypeScript, Tailwind CSS |
| **Backend** | FastAPI, Python |
| **LLM** | OpenAI GPT-4o-mini via LangChain |
| **Vector DB** | ChromaDB with SentenceTransformer embeddings |
| **Database** | PostgreSQL (SQLAlchemy ORM) |
| **Deployment** | Vercel (frontend), Railway (backend + database) |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI Server â”‚â”€â”€â”€â”€â–¶â”‚   PostgreSQL    â”‚
â”‚    (Vercel)     â”‚     â”‚    (Railway)    â”‚     â”‚   (Railway)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼            â–¼            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ ChromaDB â”‚ â”‚ LangChainâ”‚ â”‚  OpenAI  â”‚
              â”‚ (Vectors)â”‚ â”‚  (RAG)   â”‚ â”‚ GPT-4o   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Query Flow:**
1. User asks a question
2. Intent classification determines query type
3. Hybrid search retrieves relevant courses (semantic + SQL)
4. Context enrichment adds full course details
5. LLM generates natural language response

---

## Project Structure

```
mcgill_scraper/
â”œâ”€â”€ server.py              # FastAPI endpoints
â”œâ”€â”€ qa_agent.py            # LLM chain + answer generation
â”œâ”€â”€ rag_layer.py           # Hybrid search (semantic + deterministic)
â”œâ”€â”€ deterministic_logic.py # SQL-based course lookups
â”œâ”€â”€ db_setup.py            # SQLAlchemy models
â”œâ”€â”€ db_connection.py       # Database connection
â”œâ”€â”€ scraper.py             # BeautifulSoup course scraper
â”œâ”€â”€ chroma_db/             # Vector store (local)
â”œâ”€â”€ coursecraft-frontend/  # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # UI components
â”‚   â”‚   â”œâ”€â”€ lib/api.ts     # API client
â”‚   â”‚   â””â”€â”€ App.tsx        # Main app
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Key Design Decisions

**Why hybrid search?**  
Pure semantic search misses exact matches. Pure SQL can't handle fuzzy queries. Combining both gives the best of both worlds.

**Why separate prereqs and coreqs?**  
Most systems treat them the same. But "COMP 206 is a corequisite" means something different than "COMP 206 is a prerequisite." This distinction matters for accurate advising.

**Why GPT-4o-mini?**  
Fast, cheap, and smart enough for this use case. The RAG pipeline does the heavy lifting â€” the LLM just needs to synthesize the retrieved context.

---

## Future Improvements

- [ ] Video game skill-tree style course completion integration + Degree requirement tracking
- [ ] Course schedule optimization
- [ ] Multi-turn conversation memory
